<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html><head>
  <title>DSL Lecture 8</title>

  
  
  <link rel="stylesheet" href="PS_Lecture.css">

  
  <link rel="stylesheet" href="PS_Lecture.css">

</head><body>
<br>

<ul class="navbar">

  <li><a href="PS_DSL_Lecture_01.html">Lecture 1</a></li>
  <li><a href="PS_DSL_Lecture_02.html">Lecture 2</a></li>
  <li><a href="PS_DSL_Lecture_03.html">Lecture 3</a></li>
  <li><a href="PS_DSL_Lecture_04.html">Lecture 4</a></li>
  <li><a href="PS_DSL_Lecture_05.html">Lecture 5</a></li>
  <li><a href="PS_DSL_Lecture_06.html">Lecture 6</a></li>
  <li><a href="PS_DSL_Lecture_07.html">Lecture 7</a></li>
  <li><a href="PS_DSL_Lecture_08.html">Lecture 8</a></li>
  <li><a href="PS_DSL_Lecture_09.html">Lecture 9</a></li>
  <li><a href="PS_DSL_Lecture_10.html">Lecture 10</a></li>
  <li><a href="PS_DSL_Lecture_11.html">Lecture 11</a></li>
  <li><a href="PS_DSL_Lecture_12.html">Lecture 12</a></li>
</ul>

<h1>Penn State Great Valley<br>
DSL Course - Lecture 8<br>
</h1>

<hr style="width: 100%; height: 2px;">
<h1>Getting to BNF + Parser Generators &amp; Parser
Combinators</h1>

<h1><img style="width: 944px; height: 297px;" alt="Aurora" src="images/aurora/aurora/AuroraPrelude_takasaka600h.jpg"><br>
</h1>

<h2>Getting to BNF</h2>

<h3>What is BNF?</h3>

<p><br>
Backus-Naur notation (more commonly
known as BNF or Backus-Naur Form) is a formal mathematical way to
describe a language, which was developed by John Backus (and possibly
Peter Naur as well) to describe the syntax of the Algol 60 programming
language.<br>
<br>
(Legend has it that it was primarily developed by John
Backus (based on earlier work by the mathematician Emil Post), but
adopted and slightly improved by Peter Naur for Algol 60, which made it
well-known. Because of this Naur calls BNF Backus Normal Form, while
everyone else calls it Backus-Naur Form.)<br>
<br>
It is used to formally
define the grammar of a language, so that there is no disagreement or
ambiguity as to what is allowed and what is not. In fact, BNF is so
unambiguous that there is a lot of mathematical theory around these
kinds of grammars, and one can actually mechanically construct a parser
for a language given a BNF grammar for it. (There are some kinds of
grammars for which this isn't possible, but they can usually be
transformed manually into ones that can be used.)<br>
<br>
Programs that do this are commonly called "compiler compilers" or
Parser Generators (see below).&nbsp;</p>

<h3>How it works</h3>

<h4>The principles</h4>

<p>BNF
is sort of like a mathematical game: you start with a symbol (called
the start symbol and by convention usually named S in examples) and are
then given rules for what you can replace this symbol with. The
language defined by the BNF grammar is just the set of all strings you
can produce by following these rules.<br>
<br>
The rules are called production rules, and look like this:<br>
<br>
</p>

<div class="code">&nbsp; symbol := alternative1 | alternative2 ...<br>
</div>

<br>

A
production rule simply states that the symbol on the left-hand side of
the := must be replaced by one of the alternatives on the right hand
side. The alternatives are separated by |s. (One variation on this is
to use ::= instead of :=, but the meaning is the same.) Alternatives
usually consist of both symbols and something called terminals.
Terminals are simply pieces of the final string that are not symbols.
They are called terminals because there are no production rules for
them: they terminate the production process. (Symbols are often called
non-terminals.)<br>

<br>

Another variation on BNF grammars is to enclose
terminals in quotes to distinguish them from symbols. Some BNF grammars
explicitly show where whitespace is allowed by having a symbol for it,
while other grammars leave this for the reader to infer.<br>

<br>

There
is one special symbol in BNF: @, which simply means that the symbol can
be removed. If you replace a symbol by @, you do it by just removing
the symbol. This is useful because in some cases it is difficult to end
the replacement process without using this trick.<br>

<br>

So, the
language described by a grammar is the set of all strings you can
produce with the production rules. If a string cannot in any way be
produced by using the rules the string is not allowed in the language.
<h3>The BNF Highlights Again</h3>

<p>The meta-symbols of BNF are:<br>
<br>
::=&nbsp;&nbsp;&nbsp; meaning "is defined as" <br>
|&nbsp;&nbsp; &nbsp; &nbsp;&nbsp; meaning "or" <br>
&lt; &gt;&nbsp;&nbsp;&nbsp; angle brackets used to
surround category names. <br>
<br>
The angle brackets distinguish syntax rules names (also called
non-terminal symbols) from terminal symbols which are written exactly
as they are to be represented. A BNF rule defining a nonterminal has
the form:<br>
<br>
</p>

<div class="code">nonterminal ::= sequence_of_alternatives consisting
of strings of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
terminals or nonterminals separated by the meta-symbol |<br>
</div>

<br>

For example, the BNF production for a mini-language is:<br>

<br>

<div class="code">&lt;program&gt; ::=&nbsp; program<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&lt;declaration_sequence&gt;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
begin<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&lt;statements_sequence&gt;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
end ;<br>
</div>

<br>

This shows that a mini-language program consists of the keyword
"program" followed by the declaration sequence, then the keyword
"begin" and the statements sequence, finally the keyword "end" and a
semicolon.
<h3>A real example</h3>

Below is a sample BNF grammar:<br>

<p>
</p>

<div class="code"><br>
&nbsp; S&nbsp; := '-' FN |<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; FN<br>
&nbsp; FN := DL |<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; DL '.' DL<br>
&nbsp; DL := D |<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; D DL<br>
&nbsp; D&nbsp; := '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' |
'9'<br>
<br>
</div>

<br>

The
different symbols here are all abbreviations: S is the start symbol, FN
produces a fractional number, DL is a digit list, while D is a digit.<br>

<br>

Valid
sentences in the language described by this grammar are all numbers,
possibly fractional, and possibly negative. To produce a number, start
with the start symbol S:<br>

<br>

&nbsp; S<br>

<br>

Then replace the S
symbol with one of its productions. In this case we choose not to put a
'-' in front of the number, so we use the plain FN production and
replace S by FN:<br>

<br>

&nbsp; FN<br>

<br>

The next step is then to
replace the FN symbol with one of its productions. We want a fractional
number, so we choose the production that creates two decimal lists with
a '.' between them, and after that we keep choosing replacing a symbol
with one of its productions once per line in the example below:<br>

<br>

&nbsp; DL . DL<br>

<br>

&nbsp; D . DL<br>

<br>

&nbsp; 3 . DL<br>

<br>

&nbsp; 3 . D DL<br>

<br>

&nbsp; 3 . D D<br>

<br>

&nbsp; 3 . 1 D<br>

<br>

&nbsp; 3 . 1 4<br>

<br>

Here
we've produced the fractional number 3.14. How to produce the number -5
is left as an exercise for the reader. To make sure you understand this
you should also study the grammar until you understand why the string
3..14 cannot be produced with these production rules.
<h3>BNF Defined in BNF</h3>

<p>Now as a last example (maybe not the easiest to read !), here is the
definition of BNF expressed in BNF:<br>
</p>

<div class="code"><br>
syntax&nbsp;&nbsp;&nbsp;&nbsp; ::=&nbsp; { rule }<br>
rule&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
::=&nbsp; identifier&nbsp; "::="&nbsp; expression<br>
expression ::=&nbsp; term { "|" term }<br>
term&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
::=&nbsp; factor { factor }<br>
factor&nbsp;&nbsp;&nbsp;&nbsp; ::=&nbsp; identifier
|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
quoted_symbol |<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
"("&nbsp; expression&nbsp; ")" |<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
"["&nbsp; expression&nbsp; "]" |<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
"{"&nbsp; expression&nbsp; "}"<br>
identifier ::=&nbsp; letter { letter | digit }<br>
quoted_symbol ::= """ { any_character } """<br>
<br>
</div>

<h3>EBNF: What is it, and why do we need it?</h3>

<p>In
DL I had to use recursion (ie: DL can produce new DLs) to express the
fact that there can be any number of Ds. This is a bit awkward and
makes the BNF harder to read. Extended BNF (EBNF, of course) solves
this problem by adding three operators:<br>
<br>
&nbsp;&nbsp;&nbsp; ? :
which means that the symbol (or group of symbols in parenthesis) to the
left of the operator is optional (it can appear zero or one times)<br>
&nbsp;&nbsp;&nbsp; * : which means that something can be repeated any
number of times (and possibly be skipped altogether)<br>
&nbsp;&nbsp;&nbsp; + : which means that something can appear one or
more times<br>
<br>
</p>

<h3>An EBNF sample grammar</h3>

<p>So in extended BNF the above grammar can be written as:<br>
</p>

<div class="code"><br>
&nbsp; S := '-'? D+ ('.' D+)?<br>
<br>
&nbsp; D := '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'<br>
<br>
</div>

<br>

which is rather nicer. :)<br>

<br>

Just
for the record: EBNF is not more powerful than BNF in terms of what
languages it can define, just more convenient. Any EBNF production can
be translated into an equivalent set of BNF productions.<br>

<br>

<h3>Card Trick as BNF</h3>

So let's pick up where we left off in Lecture 6 about the Semantic
Model and let's follow this all the way through to the BNF for Card
Trick.&nbsp; We will use the ANTLR grammar BNF form and give you your
first peek at ANTLR.<br>

<h3>Sequence Diagram:<br>
</h3>

Use a sequence diagram to find your verbs.&nbsp; Sequence diagrams are
generally described as the tool to show interactions between objects in
the sequential order that those interactions occur.&nbsp; Developers
typically think that sequence diagrams are meant exclusively for
them.&nbsp; However, an organization's business staff can find sequence
diagrams useful to communicate how the business currently works by
showing how various business objects interact.&nbsp; From this it is
straight forward to see how sequence diagrams will aid in the
definition of a domain specific language.<br>

<br>

<br>

<img style="width: 588px; height: 613px;" alt="sequence diagram" src="images/CardTrickSequenceDiagram.jpg"><br>

<br>

The 'trick' to getting BNF of Card Trick is to look at the sequence
diagram and describe it in BNF form.&nbsp; It's obvious that everything
is some type of assignment or method call so we start there and work
our way to all the terminal elements.<br>

<br>

<div class="code"><br>
grammar CardTrick;<br>
<br>
Trick&nbsp;&nbsp;&nbsp; : Assignment | MethodCall;<br>
<br>
Assignment :&nbsp;&nbsp;&nbsp; Name '=' MethodCall;<br>
MethodCall :&nbsp;&nbsp;&nbsp; Name '.' MethodName Params;<br>
Params&nbsp;&nbsp;&nbsp;&nbsp; :&nbsp;&nbsp;&nbsp; '(' ')' | ParamList;<br>
ParamList&nbsp; :&nbsp;&nbsp;&nbsp; Param (','
Param)*;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; <br>
MethodName :&nbsp;&nbsp;&nbsp; 'shuffle' | 'print' | 'show' | 'println'
<br>
&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | 'deal'
| 'add' | 'addCards' | 'reverse'<br>
&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |
'removeCard'<br>
&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ;<br>
Param&nbsp;&nbsp;&nbsp; &nbsp; :&nbsp;&nbsp;&nbsp; Number | Name
| Constant;<br>
Name&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; :&nbsp;&nbsp;&nbsp; ('a'..'z' |
'A'..'Z' | '0'..'9')+;<br>
Number&nbsp;&nbsp;&nbsp;&nbsp; :&nbsp;&nbsp;&nbsp; ('0'..'9')+
Qualifier?;<br>
Qualifier&nbsp; :&nbsp;&nbsp;&nbsp; '.' ('card' | 'cards');<br>
Constant&nbsp;&nbsp; :&nbsp;&nbsp;&nbsp; 'ADD_TO_TOP' | 'ADD_TO_BOTTOM'
| 'TOP_CARD';&nbsp;&nbsp;&nbsp; <br>
<br>
</div>

<br>

It is very similar to building out a DTD or XML schema.&nbsp; The end
product represents metadata and is a description.&nbsp; It can be used
to find errors, validate or parse the data it represents.&nbsp; There
is definitely an advantage to having some experience in creating these
forms and the skills are worth pursuing.<br>

<br>

<h2>Parser Generators</h2>

<p>So now you have your grammar file, the natural way of describing the
syntactic structure of a DSL.&nbsp; Once you have a grammar, it's
tedious work to turn it into a handwritten parser, and tedious work
should be done by a computer!</p>

<p>A parser generator uses this grammar file to generate a
parser.&nbsp; The parser can be updated merely by updating the grammar
and regenerating.&nbsp; The generated parser can use efficient
techniques that would be hard to build and maintain by hand.<br>
</p>

<p>The purpose of this section is not to show or teach you how to
build your own Parser Generator but to introduce you to them and what
they offer you. &nbsp;Parser Generators are common tools that take
your grammar file (for example, BNF) to generate a parser.</p>

<p>In computer science, a parser generator or a compiler-compiler
or compiler generator is a
tool that creates a parser, interpreter, or compiler from some form of
formal description of a language and machine. The earliest and still
most common form is a parser generator, whose
input is a grammar (usually in BNF) of a programming language, and
whose generated output is the source code of a parser often used as a
component of a compiler.</p>

<p>The usual way to work with a Parser Generator is to write a
grammar file. &nbsp;This file will likely use a particular form of
BNF used by that Parser Generator. &nbsp;There is no
standardization here so if you change your parser generator you will
likely have to rewrite your grammar.</p>

<p>Once you have a grammar, the usually route is to use the parser
generator to generate a parser. &nbsp;Most parser generators use
code generation which allows them&nbsp;to output to different host
languages. &nbsp;There is no reason why a parser generator
shouldn't be able to read a grammar file at runtime and interpret it,
then build a parser combinator (more in next section).</p>

<p>Generally, you treat the generated code as black box and don't
delve into it. &nbsp;It is, however, &nbsp;useful to follow
what the parser is doing - particularly if you are trying to debug your
grammar. &nbsp;In this case, there is an advantage in the parser
generator using an algorithm that is easier to follow, such as
generating a Recursive Descent Parser.</p>

<p>The greatest advantage to using a parser generator is that it
provides
an explicit grammar to define the syntactic structure of the language
you are processing. &nbsp;This is the key advantage of using a DSL.
&nbsp;Since
parser generators are primarily designed to handle complicated
languages, they also give you much more features and power than you
would get by writing your own parser. &nbsp;These features may
require some
effort to learn, you can usually start with a simple set and work your
way up from there. Parser Generators may provide good error handling
and diagnostics which can make a big difference when trying to figure
out why your grammar isn't doing what you think it should.
</p>

<p>In the last lecture we will look at ANTLR parser generator.
&nbsp;We would recommend ANTLR to anyone who wants to explore
parser generators. &nbsp;ANTLR outputs to a variety of host
languages; ANTLR is a mature tool with excellent documentation; ANTLR
is free and easy to download and install.</p>

<h3>Variants and History<br>
</h3>

<p>A typical parser generator associates executable code with
each of
the rules of the grammar that should be executed when these rules are
applied by the parser. These pieces of code are sometimes referred to
as semantic action routines since they define the semantics of the
syntactic structure that is analyzed by the parser. Depending upon the
type of parser that should be generated, these routines may construct a
parse tree (or abstract syntax tree), or generate executable code
directly.<br>
<br>
One of the earliest (1964), surprisingly powerful, versions of
a compiler-compiler is MetaII, which accepted grammars and code
generation rules, and is able to compile itself and other languages.<br>
<br>
Some experimental compiler-compilers take as input a formal description
of programming language semantics, typically using denotational
semantics. This approach is often called 'semantics-based compiling',
and was pioneered by Peter Mosses' Semantic Implementation System (SIS)
in 1978. However, both the generated compiler and the code it
produced were inefficient in time and space. No production compilers
are currently built in this way, but research continues.<br>
<br>
The Production Quality Compiler-Compiler project at Carnegie-Mellon
University does not formalize semantics, but does have a semi-formal
framework for machine description.<br>
<br>
Compiler-compilers exist in many flavors, including bottom-up rewrite
machine generators (see <a href="http://jburg.sourceforge.net/">JBurg</a>)
used to tile syntax trees according to a
rewrite grammar for code generation, and attribute grammar parser
generators (e.g. ANTLR can be used for simultaneous type checking,
constant propagation, and more during the parsing stage).<br>
</p>

<p>The first compiler-compiler to use that name was written by
Tony
Brooker in 1960 and was used to create compilers for the Atlas computer
at the University of Manchester, including the Atlas Autocode compiler.
However it was rather different from modern compiler-compilers, and
today would probably be described as being somewhere between a highly
customizable generic compiler and an extensible-syntax language. The
name 'compiler-compiler' was far more appropriate for Brooker's system
than it is for most modern compiler-compilers, which are more
accurately described as parser generators. It is almost certain that
the "Compiler Compiler" name has entered common use due to Yacc rather
than Brooker's work being remembered.<br>
</p>

Probably the most well known and widely used parser generator is YACC
or Yet Another Compiler Compiler.&nbsp; YACC was written in the 1975 by
Stephen C. Johnson at Bell Labs for the the Unix operating
system.&nbsp; It generates a parser based on an analytic grammar
written in a notation similar to BNF.&nbsp; YACC used to be available
on all Unix system but lately it has been supplanted by Berkeley Yacc,
GNU Bison and MKS Yacc.
<p><img style="width: 473px; height: 396px;" alt="Compilation Sequence" src="images/compilationSeq.gif"><br>
</p>

<p>
Other examples of parser generators in the yacc vein are ANTLR, Coco/R,
CUP, GNU Bison, Eli, FSL, SableCC and JavaCC.</p>

<h2>Parser Combinator</h2>

Parser combinators are one of the most beautiful applications of
functional programming.&nbsp; They offer an internal DSL a tool used
for designing external DSLs so you don&#8217;t have to implement your own
language infrastructure as you do with other techniques of external DSL
design. When we look at ANTLR we will design our grammar for the DSL
and ANTLR will&nbsp; generate the parser for us. To design our own DSL,
we have to use an external tool to provide the necessary language
implementation infrastructure. Using parser combinators, you don&#8217;t have
to step out of the host language for a second. This makes the
implementation succinct, expressive, and completely free of any
external dependency.<br>

<br>

A parser is an engine that works on an input stream and consumes a
collection of tokens. It can either recognize the stream of tokens as
part of a valid language identified by the parser, or it can reject the
input as soon as it encounters an invalid symbol. In either case, the
parser returns a result (success or failure), along with a truncated
stream containing the rest of the input not yet consumed. When the
parser returns a success, you can feed the truncated input stream to
yet another parser that can potentially consume the rest of the input.
In the case of a failure, you can rewind to the beginning of the stream
and try parsing with another parser. Because parsers work this way, you
can chain them in a variety of ways to parse a complete input stream. <br>

<br>

Chaining parsers. Parser #1 parses a part of the input stream. Parser
#2 matches the part left over by parser #1. The combination returns a
parser that combines the two results. The combination parser succeeds
only if both parser #1<br>

and parser #2 match their inputs.<br>

<br>

<img style="width: 623px; height: 591px;" alt="Parser Combinator" src="images/ParserCombinator.jpg"><br>

<br>

Because it&#8217;s a function of its input, a parser can compose with other
parsers and evolve the syntax of our DSL in a piecemeal way.<br>

<br>

Let&#8217;s look at the problem of composing parsers in a functional way. In
functional programming, a parser is a function that takes input and
produces a result. Parser combinators allow you to use higher-order
functions (also known as combinators) in a purely compositional way to
construct grammar structures such as sequencing, repetitions,
optionality, and choice. If your language of implementation supports
infix operator notation, then a grammar rule written using parser
combinators resembles an EBNF production.<br>

<br>

The biggest advantage of parsing with combinators is improved
composability; you take primitive parsers and compose them functionally
to generate larger ones. Composing with combinators is like building
with LEGOs&#8212;we start with smaller pieces and build higher-order
structures out of them.<br>

<br>

In the world of DSL design, you can use parser combinators to compose
smaller language fragments that model parts of your DSL syntax and
build the whole DSL structure out of them. The sequence combinator that
you see in figure 8.2 is only one such combinator, which is shown in
the figure composing two DSL syntax parsers sequentially. Any standard
implementation includes a variety of such combinators, much like LEGO
sets.<br>

<p>Parsers built using combinators are straightforward to
construct,
&#8216;readable&#8217;, modular, well-structured and easily maintainable. They have
been used extensively in the prototyping of compilers and processors
for domain-specific languages such as natural language interfaces to
databases, where complex and varied semantic actions are closely
integrated with syntactic processing. In 1989, Richard Frost and John
Launchbury demonstrated use of parser combinators to construct
natural language interpreters. Graham Hutton also used higher-order
functions for basic parsing in 1992.&nbsp; S.D. Swierstra also
exhibited
the practical aspects of parser combinators in 2001.&nbsp; In 2008,
Frost,
Hafiz and Callaghan described a set of parser combinators in Haskell
that solve the long-standing problem of accommodating left recursion,
and work as a complete top-down parsing tool in polynomial time and
space.<br>
<br>
</p>

<h3>Basic idea</h3>

<p>In functional programming, parser combinators can be used to
combine
basic parsers to construct parsers for more complex rules. For example,
a production rule of a context-free grammar (CFG) may have one or more
&#8216;alternatives&#8217; and each alternative may consist of a sequence of
non-terminal(s) and/or terminal(s), or the alternative may consist of a
single non-terminal or terminal or the empty string. If a simple parser
is available for each of these alternatives, a parser combinator can be
used to combine each of these parsers, returning a new parser which can
recognize any or all of the alternatives.<br>
<br>
A parser combinator can take the form of an infix operator, used to
&#8216;glue&#8217; different parsers to form a complete rule. Parser combinators
thereby enable parsers to be defined in an embedded style, in code
which is similar in structure to the rules of the grammar. As such,
implementations can be thought of as executable specifications with all
of the associated advantages.<br>
</p>

<h3>Shortcomings and solutions</h3>

<p>Parser combinators, like all recursive descent parsers, are
not
limited to the context-free grammars and thus do no global search for
ambiguities in the LL(k) parsing Firstk and Followk sets. Thus,
ambiguities are not known until run-time if and until the input
triggers them. In such cases, the recursive descent parser defaults
(perhaps unknown to the grammar designer) to one of the possible
ambiguous paths, resulting in semantic confusion (aliasing) in the use
of the language. This leads to bugs by users of ambiguous programming
languages, which are not reported at compile-time, and which are
introduced not by human error, but by ambiguous grammar. The only
solution which eliminates these bugs is to remove the ambiguities and
use a context-free grammar.<br>
<br>
<br>
<br>
</p>

<address>by D Bartlett.</address>

</body></html>