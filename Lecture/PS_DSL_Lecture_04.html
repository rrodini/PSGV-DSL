<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html><head>
  <title>DSL Lecture 4</title>

  
  
  <link rel="stylesheet" href="PS_Lecture.css">

</head><body>
<!-- Site navigation menu -->
<ul class="navbar">

  <li><a href="PS_DSL_Syllabus.html">Syllabus</a></li>
  <li><a href="PS_DSL_Lecture_01.html">Lecture 1</a></li>
  <li><a href="PS_DSL_Lecture_02.html">Lecture 2</a></li>
  <li><a href="PS_DSL_Lecture_03.html">Lecture 3</a></li>
  <li><a href="PS_DSL_Lecture_05.html">Lecture 5</a></li>
  <li><a href="PS_DSL_Lecture_06.html">Lecture 6</a></li>
  <li><a href="PS_DSL_Lecture_07.html">Lecture 7</a></li>
  <li><a href="PS_DSL_Lecture_08.html">Lecture 8</a></li>
  <li><a href="PS_DSL_Lecture_09.html">Lecture 9</a></li>
  <li><a href="PS_DSL_Lecture_10.html">Lecture 10</a></li>
</ul>

<!-- Main content -->
<h1>Penn State Great Valley<br>
DSL Course - Lecture 4</h1>

<img style="width: 600px; height: 391px;" alt="aurora" src="images/aurora/aurora/aurora-borealis-over-snow-covered-road-600w.jpg"><br>

<br>

<h2>Implementing External DSLs</h2>

Implementing an external DSL differs
from internal DSLs in that the parsing process operates on pure text
input which is not constrained by any particular language.
&nbsp;The
techniques we can use to parse text are essentially those that have
been in use for decades in parsing programming languages.
&nbsp;There
is also a long-running language community developing these tools and
techniques.<br>

<br>

But there is a catch. &nbsp;The tools and writings
of the programming language community almost always assume your are
working with a general-purpose language. &nbsp;DSLs are lucky to
get
mention in passing. &nbsp;While many of the principles apply
equally to
general-purpose and domain-specific languages, there are differences.
&nbsp;In addition, you don't need to go all the way up the learning
curve that you'd need to go for a general-purpose language.
<h2>An example<br>
<span style="text-decoration: underline;"></span></h2>

The simplest way is to divide the input text into lines then process
each line. &nbsp;As an example let's use the well worn DSL known as
<span style="font-style: italic; font-weight: bold;">make</span>.
&nbsp;You need a file called a makefile to tell <span style="font-weight: bold; font-style: italic;">make</span>
what to do. &nbsp;Most often, the makefile tells <span style="font-weight: bold; font-style: italic;">make</span>
how to compile and link a program, most famously&nbsp;in C or C++.
&nbsp;Let's say we have a simple makefile that describes how to
compile and link a text editor which consists of eight C source files
and three header files. &nbsp;The makefile can also tell <span style="font-weight: bold; font-style: italic;">make</span>
how to run miscellaneous commands when explicitly asked, for example,
to remove certain files as a clean-up operation.<br>

<br>

When <span style="font-weight: bold; font-style: italic;">make</span>
recompiles the editor, each changed C source file must be recompiled.
&nbsp;If a header file has changed, each C source file that
includes the header must be recompiled to be safe. &nbsp;Each
compilation produces an object file corresponding to the source file.
&nbsp;Finally, if any source file has been recompiled, all the
object files, whether newly made or saved from previous compilations,
must be linked together to produce the new executable editor.<br>

<br>

The text above represents the "domain" of <span style="font-weight: bold; font-style: italic;">make</span>.
In there are all the nouns and verbs needed to determine what our
syntax will be. &nbsp;Mostly <span style="font-weight: bold; font-style: italic;">make</span>
is about dependencies and rules. &nbsp;A simple makefile consists
of rules with the following shape:<br>

<br>

<span class="code"><br>
target ... : dependencies ...<br>
&nbsp;&nbsp;command<br>
&nbsp;&nbsp;...<br>
&nbsp;&nbsp;...<br>
</span><br>

A target is usually the name of a file that is generated by a program;
examples of targets are executable or object files. &nbsp;A target
can also be the name of an action to carry out, such as clean.
&nbsp;A
subset of target is a goal. &nbsp;Goals are targets that <span style="font-weight: bold; font-style: italic;">make</span><span style="font-weight: bold; font-style: italic;"> </span>strives
ultimately to update.<br>

<br>

A dependency is a file that is used as input to a create the target.
&nbsp;A target depends on several files.<br>

<br>

A command is an action that make carries out. &nbsp;A rule may have
more than one command, each on its own line. &nbsp;With <span style="font-weight: bold; font-style: italic;">make&nbsp;</span>
you need to put a tab character at the beginning of every command line!
&nbsp;<span style="color: white;">So it is important
to understand that when it comes to&nbsp;syntax those
items&nbsp;which you cannot see may be just as important as those
you can see!! <br>
</span><br>

Usually a command is in a rule with dependencies and serves to create a
target file if any of the dependencies change. &nbsp;However, the
rule that specifies commands for the target need not have dependencies.
&nbsp;For example, the rule containing the delete command
associated with the target 'clean' does not have dependencies.<br>

<br>

Lastly a rule explains how and when to remake certain files which are
the targets of the particular rule. &nbsp;<span style="font-weight: bold; font-style: italic;">make </span>carries
out the commands on the dependencies to create or update the target.
&nbsp;A rule can also explain how and when to carry out an action.<br>

<br>

An example is in order:<br>

<br>

<br>

<span class="code">&nbsp;edit : main.o kbd.o command.o
display.o \<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
insert.o search.o files.o utils.o<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -o edit main.o kbd.o command.o display.o \<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
insert.o search.o files.o utils.o<br>
&nbsp;&nbsp;&nbsp;&nbsp; <br>
&nbsp;&nbsp;&nbsp;&nbsp; main.o : main.c defs.h<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -c main.c<br>
&nbsp;&nbsp;&nbsp;&nbsp; kbd.o : kbd.c defs.h command.h<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -c kbd.c<br>
&nbsp;&nbsp;&nbsp;&nbsp; command.o : command.c defs.h
command.h<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -c command.c<br>
&nbsp;&nbsp;&nbsp;&nbsp; display.o : display.c defs.h
buffer.h<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -c display.c<br>
&nbsp;&nbsp;&nbsp;&nbsp; insert.o : insert.c defs.h
buffer.h<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -c insert.c<br>
&nbsp;&nbsp;&nbsp;&nbsp; search.o : search.c defs.h
buffer.h<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -c search.c<br>
&nbsp;&nbsp;&nbsp;&nbsp; files.o : files.c defs.h
buffer.h command.h<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -c files.c<br>
&nbsp;&nbsp;&nbsp;&nbsp; utils.o : utils.c defs.h<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cc -c utils.c<br>
&nbsp;&nbsp;&nbsp;&nbsp; clean :<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
rm edit main.o kbd.o command.o display.o \<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
insert.o search.o files.o utils.o<br>
<br>
</span>
A long line is split into two line using the backslash-newline; this is
like using one long line, but easier to read.<br>

<br>

To use this makefile to delete the executable file and all the object
files from the directory, type:<br>

&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; <span style="font-style: italic;"><span style="font-weight: bold;">make clean</span></span><br>

<br>

In
the example makefile, the targets include the executable file 'edit',
and the object files 'main.o', and 'kbd.o'. &nbsp;The dependencies
are
files such as 'main.c' and 'defs.h'. &nbsp;In fact, each ' .o' file
is
both a target and a dependency. &nbsp;Command include 'cc -c
main.c'
and 'cc -c kbd.c'.<br>

<br>

When a target is a file, it needs to be
recompiled or relinked if any of its dependencies change. &nbsp;In
addition, any dependencies that are themselves &nbsp;automatically
generated should be updated first. &nbsp;In this example, 'edit'
depends on each of the eight object files; the object file 'main.o'
depends on the source file 'main.c' and on the header file 'defs.h'.<br>

<br>

The
target 'clean' is not a file, but merely the name of an action.
&nbsp;Since you normally do not want to carry out the actions in
this
rule, 'clean' is not a dependency of any other rule.
&nbsp;Consequently, <span style="font-weight: bold; font-style: italic;">make</span>
never
does anything with it unless you tell it specifically. &nbsp;Note
that
this rule not only is not a dependency, it also does not have any
dependencies, so the only purpose of the rule is to run the specified
commands. &nbsp;Targets that do not refer to files but are just
actions
are called <span style="font-style: italic;">phony targets</span>.<br>

<br>

<h4>How <span style="font-style: italic;">make</span>
Processes a
Makefile</h4>

By default, <span style="font-weight: bold; font-style: italic;">make</span><span style="font-weight: bold; font-style: italic;">&nbsp; </span>starts
with the first target (not targets whose names start with '.').
&nbsp;This is called the default goal. In the example, the default
goal
is to update the executable program 'edit'; therefore, we put that rule
first.<br>

<br>

Thus when you give the command:<br>

<br>

&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; <span style="font-weight: bold; font-style: italic;">make</span><br>

<span style="font-weight: bold; font-style: italic;"></span><br>

<span style="font-weight: bold; font-style: italic;">make</span><span style="font-weight: bold; font-style: italic;"> </span>reads
the makefile in the current directory and begins by processing the
first rule. &nbsp;In the example, this rule is for relinking
'edit';
but before <span style="font-weight: bold; font-style: italic;">make</span>
can fully process this rule, it must process the rules for the files
that 'edit' depends upon, which in this case are the object files.
&nbsp;Each of these files is processed according to its own rule.
&nbsp;These rules say to update each ' .o' file by compiling its
source
file. &nbsp;The recompilation must be done if the source file, or
any
of the header files named as dependencies, is more recent than the
object file, or if the object file does not exist.<br>

<br>

The other
rules are processed because their targets appear as dependencies of the
goal. &nbsp;If some other rule is not depended on by the goal, that
rule is not processed, unless you tell <span style="font-weight: bold; font-style: italic;">make</span>
to do so
with a command such as <span style="font-weight: bold; font-style: italic;">make clean.</span><br>

<br>

Before recompiling an object file, <span style="font-weight: bold; font-style: italic;">make&nbsp;</span>
considers updating its dependencies, the source file and header files.
&nbsp;This makefile does not specify anything to be done for them -
the
' .c' and &nbsp;' .h' files are not the targets of any rules so <span style="font-weight: bold; font-style: italic;">make</span>
does
nothing for these files.<br>

<br>

After recompiling whichever object files need it, <span style="font-weight: bold; font-style: italic;">make</span>&nbsp;<span style="font-weight: bold; font-style: italic;"></span>decides
whether to relink 'edit'. &nbsp;This must be done if the file
'edit'
does not exist, or if any of the object files are newer than it.
&nbsp;If an object file was just recompiled, it is now newer than
'edit', so 'edit' is relinked.<br>

<br>

This if we change the file 'insert.c' and run <span style="font-weight: bold; font-style: italic;">make,</span>
<span style="font-weight: bold; font-style: italic;">make</span>
will
compile that file to update 'insert.o' and then link 'edit'.
&nbsp;If
we change the file 'command.h' and run <span style="font-weight: bold; font-style: italic;">make, </span><span style="font-weight: bold; font-style: italic;">make </span>will
recompile the object files 'kbd.o', 'command.o' and 'files.o' and then
link the file 'edit'.<br>

<br>

<h2><span style="text-decoration: underline;">Syntactic
Analysis
Strategy</span></h2>

What you should be seeing from this example is that each line in our
make files tells us something specific in our DSL. &nbsp;<span style="font-weight: bold; font-style: italic;">edit : </span>&nbsp;is
a definition of a target and to exact our goal target.
&nbsp;Syntactic
analysis is about recognizing the different parts of our DSL and
creating actions from those parts. &nbsp;Initially
we must parse an external DSL. &nbsp;We need to take the stream of
text
and break it up into some kind of structure that we can use to figure
out what that text says. &nbsp;This initial structuring is referred
to
as syntactic analysis.<br>

<h3>Delimiter-Directed Translation</h3>

The simplest way to do syntactic analysis
is something you have probably all done. &nbsp;Divide the input
text
into lines, then process each line. &nbsp;With <span style="font-weight: bold; font-style: italic;">make</span>
you know that if it starts with a tab then you are dealing with a
command. &nbsp;You then break up the line accordingly to find the
key
bits of information. &nbsp;This style is referred by Fowler as
Delimiter-Directed Translation. &nbsp;The general idea is to pick
some
delimiter characters that break the input into statements (usually line
endings), chop the input into separate statements using that delimiter,
and then feed each chunk into a separate processing step to figure out
what's on the line. &nbsp;Usually, there's some clear marker in the
line that tells you what kind of statement you are dealing with.<br>

<br>

Delimiter-Directed Translation is very simple to use and uses tools
that most programmers are familiar with - string splitting and regular
expressions.&nbsp; Its limitation is that it doesn't give you any
inherent way to handle the hierarchic context of your input.<br>

<br>

From the example above you can see that 'edit' depends on 'main.0'
which depends on 'main.c', so you can see there is a rudimentary
hierarchy building here.&nbsp; Complex makefiles have complex
hierarchies.<br>

<br>

<h3>Syntax-Directed Translation<br>
</h3>

In order to handle DSLs with more complex structures we use a technique
called Syntax-Directed Translation.&nbsp; In this technique, we
first
define a formal grammar for the input language.&nbsp; For our
example,
it would look something like this:<br>

<br>

<br>

<span class="code"><br>
target ... : dependencies ...<br>
&nbsp;&nbsp;command<br>
&nbsp;&nbsp;...<br>
&nbsp;&nbsp;...<br>
</span><br>

Looks familiar right!&nbsp; This is called the Backus-Naur Form
or BNF.&nbsp; It is a way of writing grammars to define the syntax
of
a language.&nbsp; It was invented to describe Algol in 60s and
since
then it has been widely used&nbsp; for both explanation and to
drive
Syntax-Directed Translation.<br>

<br>

As another example, let's create a US postal address in BNF:<br>

<br>

<span class="code"><br>
&lt;postal-address&gt; ::= &lt;name-part&gt;
&lt;street-address&gt;
&lt;zip-part&gt;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&lt;name-part&gt; ::=
&lt;personal-part&gt; &lt;last-name&gt;
&lt;opt-suffix-part&gt;
&lt;EOL&gt; <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
| &lt;personal-part&gt; &lt;name-part&gt;<br>
&nbsp;<br>
&nbsp; &lt;personal-part&gt; ::= &lt;first-name&gt;
| &lt;initial&gt;
"." <br>
&nbsp;<br>
&nbsp;&lt;street-address&gt; ::= &lt;house-num&gt;
&lt;street-name&gt;
&lt;opt-apt-num&gt; &lt;EOL&gt;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&lt;zip-part&gt; ::=
&lt;town-name&gt; "," &lt;state-code&gt;
&lt;ZIP-code&gt; &lt;EOL&gt;<br>
&nbsp;<br>
&lt;opt-suffix-part&gt; ::= "Sr." | "Jr." |
&lt;roman-numeral&gt; | ""<br>
<br>
</span>
<br>

Like everything else in life and computer science, BNF can get complex
quickly.&nbsp; You don't have to be an expert at BNF creation but
you
have to know what it is and how to decipher it.<br>

<br>

In BNF, each line is a production rule; it states a name followed by
the legal elements of that rule.&nbsp; In <span style="font-style: italic; font-weight: bold;">make</span>,
the
production rules define targets - they have dependencies - and
commands, which are those things that must be executed to create the
dependencies or targets.<br>

<br>

So let us take a quick attempt at creating a BNF for <span style="font-weight: bold; font-style: italic;">make</span>:<br>

<br>

<br>

<span class="code"><br>
Makefile : variable | rule | conditional | include | whitespace |
newline;<br>
<br>
variable: symbol opt-whitespace equals opt-whitespace element-list;<br>
<br>
rule: targets opt-whitespace colons opt-whitespace element-list
commands;<br>
<br>
targets: target opt-whitespace targets;<br>
<br>
target: sub-target target;<br>
<br>
commands: shell-command newline commands;<br>
<br>
</span>
<br>

<br>

<img style="width: 50px; height: 63px;" alt="Question" src="images/question_mark.jpg">&nbsp;Quick-Stop Quiz! -
Do you recognize this structure from some other technology? &nbsp;<br>

<br>

<img style="width: 50px; height: 63px;" alt="Question" src="images/question_mark.jpg">&nbsp;Quick-Stop
Quiz! - Ok so now we have a structure (BNF) to define grammar.
&nbsp;That means we can use the BNF structure as a what?<br>

<br>

<br>

Back to Syntax-Directed Translation - we have been defining a grammar
and a grammar is a good way of thinking about the syntax of a language.
&nbsp;It works particularly well for Syntax-Directed Translation
because you can translate it fairly mechanically into a parser.<br>

<br>

The
kind of parser that is generated from Syntax-Directed Translation is
very capable of handling hierarchic structures like there; after all,
this kind of thing is essential for general-purpose languages. As a
result, you can handle many things that are awkward with
Delimiter-Directed Translation more easily.<br>

<br>

<h4>Grammars</h4>

Quick Definitions:<br>

<br>

<ul>

  <li>Terminal Symbols -&nbsp;are literal characters
that can appear in the inputs to or outputs from the production rules
of a formal grammar and that cannot be broken down into "smaller"
units. &nbsp;Terminal symbols are synonymous with "tokens" in
syntactic analysis.</li>
  <li>Nonterminal Symbols - or just nonterminals, are the symbols
which can be replaced; thus there are strings composed of some
combination of terminal and nonterminal symbols. They may also be
called simply syntactic variables.</li>
</ul>

<br>

Let's
take a moment to explicitly define "grammars", which will take us
briefly into language theory. The Chomsky hierarchy, was
developed by linguist Noam Chomsky in the 1950's. It
was based on looking at natural languages, not computer languages, but
it derives
its classification from the mathematical properties of a grammar used
to define their syntactic structure.<br>

<br>

Regular, context-free, and
context-sensitive are the tree categories taht concern DSL development.
They form a hierarchy, in that all grammars that are regular
are context-free, and all grammars that are context-free are
context-sensitive:<br>

<br>

context-sensitive -&gt; context-free -&gt; regular<br>

<br>

The
Chomsky hierarchy strictly applies to grammars, but people use it for
languages too. &nbsp;To say that a language is regular means that
you
can write a regular grammar for it.<br>

<br>

The difference between
classes depends on certain mathematical characteristics of the grammar.
&nbsp;I'll leave that to proper language books to explain; for the
purposes of this class, the key distinction is <span style="font-weight: bold;">what kind of fundamental
algorithm you need for the parser</span>.<br>

<br>

<h5>Regular Grammar</h5>

A
regular grammar is important because it can be processed using a finite
state machine. &nbsp;This is important because regular expressions
are
finite-state machines, hence a regular language can be parsed using
regular expressions.<br>

<br>

In terms of computer languages, regular
grammars have one big problem: They can't deal with nested elements.
&nbsp;A regular language can parse an expression like 1+ 2 * 3 + 4
but
cannot parse 1 + (2 * (3 + 4). &nbsp;You may hear people saying
that
regular grammars 'can't count'. &nbsp;In parsing terms this means
that
you can't use a finite-state machine to parse a language that has
mested blocks. &nbsp;Obviously, this is a bit of a bummer when it
comes
to computer languages, as any general-purpose language has to be able
to do arithmetic. &nbsp;It also affects block structure - programs
that
need nested blocks are not regular.<br>

<h5>Context-Free Grammars</h5>

To
handle nested blocks, ou need to step up to a context-free grammar.
&nbsp;A context-free grammar does add hierarchic context to your
grammar, allowing it to 'count' so the name can be a bit confusing.
&nbsp;A context-free grammar can be implemented using a push-down
machine, which is a finite-state machine with a stack. &nbsp;Most
language parsers use context-free grammars, most Parser Generators use
them, and both Recursive Decent Pasers and Parser Combinator produce a
push-down machine. &nbsp;As a result, most modern programming
languages
are parsed using context-free grammars.<br>

<br>

I doubt your DSL will
stray beyond a Context-Free grammar but if it does then you are
probably asking the grammar to declare a variable before you use it.
&nbsp;The problem here is that the declaration of a variable often
occurs outside the particular branch of the hierarchy you are in when
you use the variable. &nbsp;While a context-free grammar can hold
hierarchic context, that's not enough context to handle this case - you
need a symbol table - and a context-sensitive grammar.<span style="font-weight: bold;"><br>
</span>
<h5><span style="font-weight: bold;">C</span>ontext-Sensitive
Grammar</h5>

We arrive at the most general element&nbsp;of the Chomsky hierarchy
which is context-sensitive grammar. Since this comes from the "natural"
language world this means that a word takes on different definitions
based upon its context. &nbsp;This is classic "Get Smart" stuff
with Hymie the Robot who cannot put any command he is given in context.
&nbsp;Max says "Hymie, kill the light." and he puts a bullet in the
light. Yes, late '60s humor but relavent here because this is the end
of the road. &nbsp;We don't know how to write general
context-sensitive parsers.<br>

<br>

All this gives you the insight you need to determine which tool to use
for processing a DSL:<br>

<ul>

  <li>If you are dealing with a regular grammar in which clearly
defined inputs result in clearly defined outputs then you can use a
Delimiter-Directed Translation.</li>
  <li>If you need nested blocks, you'll need something that can
handle a context-free grammar. &nbsp;In this case you are going to
want to use a Syntax-Directed Translation.</li>
  <li>Lastly, you should realize that creating a push-down
machine is rather straight forward once you get used to them.
&nbsp;As you gain experience, you may want to use a push-down
machine associated with Syntax-Directed Translations for extensive
regular grammars.</li>
</ul>

<h4>Parsing</h4>

The
big question is "How do you go from a grammar to a parser?
&nbsp;There
is tons of research into this over many years. &nbsp;Much of it
comes
from general-purpose languages and compiler writing. &nbsp;All the
work
has spawned lots of techniques. &nbsp;Fowler selected three so
let's
look at those:<br>

<br>

<h5>Recursive Descent Parser</h5>

Recursive
descent parser is a classic way to perform this conversion.
&nbsp;The
recursive descent algorithm is an easy to understand approach to
parsing that takes the grammar rule and turns it into a function in the
parser, and there are clear patterns you follow to turn each BNF
operator into control flow.<br>

<br>

A recursive descent parser supports
the flexibility of an external DSL without requiring a Parser Generator
(see below). &nbsp;The Recursive Descent Parser can be implemented
in
whatever general-purpose language one chooses. &nbsp;It uses
control
flow operators to implement the various grammar operators.
&nbsp;Individual methods or functions implement the parsing rules
for
the different nonterminal symbols in the grammar.<br>

<br>

The
basic structure of a Recursive Descent Parser is quite simple.
&nbsp;There is a method for each nonterminal symbol in the grammar.
&nbsp;This method implements the various production rules associated
with the nonterminal. &nbsp;The method returns a Boolean value which
represents teh result of the match. &nbsp;Failure at any level gets
propagated back up the call stack. Each method operates on the token
buffer, advancing the pointer through the tokens as it matches some
portion of the sentence.<br>

<br>

Fowler does a good job of describing
the limited processing alternatives (page 246) and how they create a
small number of patterns.<br>

<h5>Parser Combinator</h5>

The
second, more modern and hip method is the Parser Combinator.
&nbsp;Here, each rule is turned into an object, and we compose the
objects into a structure that mirrors that grammar. &nbsp;You still
need the elements of the Recursive Decent Parser, but these are
packaged up into combinator objects that you can just compose together.
&nbsp;This allows you to implement a grammar without knowing the
details of the Recursive-Decent Parser algorithms.<br>

<br>

A Parser Combinator implements a grammar using a structure of parser
objects. &nbsp;Recognizers for the symbols in the production rules are
combined using the Composite design pattern and are referred to as
combinators. &nbsp;Effectively, parser combinators represent the
semantic
model of a grammar.<br>

<br>

Each
combinator is responsible for recognizing some portion of the language,
determining if there is a match, consuming the relevant tokens from the
input buffer for the match, and perforing the required actions.<br>

<br>

Rebecca Parsons (Fowler's book) main premise is that Parser
Generators are not nearly as difficult to work with as they are
perceived to be but there are legitimate reasos to avoid them if
possible. &nbsp;The most obvious issue is the additional steps in the
build process required to first generate the parser and then build it.
&nbsp;Parser Generators are still the right choice for more complex
context-free grammars, particularly if the grammar is ambiguous or
performance is crucial, directly implementing a parser in a
general-purpose language is a viable option.<br>

<h5>Parser Generator</h5>

A
parser generator takes a flavor of BNF and uses it as a DSL.
&nbsp;you
write your grammar in this DSL, and the Parser Generator then generates
a parser for you.<br>

<br>

The parser generator approach is the most
sophisticated approach; such tools are very mature and can handle
complex languages very efficiently. &nbsp;Using BNF as a DSL makes
it
easy to understand and maintain the language, since its syntax is
clearly defined and automatically tied to the parser. &nbsp;On the
downside, they do take a bit of time to learn and, since they mostly
use code generation, they complicate the build process. &nbsp;You
may
not have a good Parser Generator available for your language platform,
and it's not trivial to write one yourself.<br>

<br>

The usualy way to work with a Parser Generator is to write a grammar
file. &nbsp;This file will use a particular form of BNF used by that
Parser Generator. &nbsp;There is no standardization for these BNF
formats; so if you change your parser generator, you will have to write
a&nbsp;new grammar.<br>

<br>

Once you have a grammar, the usual route is
to use the Parser Generator to generate a parser. &nbsp;Most Parser
Generators use code generation, which may allow you to generate a
parser in different host languages. Parser Generators use code
generation due to a mix of tradition and performance considerations -
particularly since they are usually aimed at general-purpose languages.<br>

<br>

The
Parser Generator used in the book and used in this class is ANTLR.
&nbsp;ANTLR is easily available, has lots of documentation and has been
around a good while. &nbsp;There is also an IDE-style tool
(ANTLR-Works) that provides some UI streamlineing for developing
grammars.<br>

<br>

<br>

A Simple Example<br>

<br>

We can implement syntax-directed translation in either a top-down or a
bottom-up <br>

parser and we'll briefly investigate each approach.&nbsp; First, let's
look at adding attribute <br>

information to a hand-constructed top-down recursive-descent
parser.&nbsp; Our example <br>

will be a very simple FTP client, where the parser accepts user
commands and uses a <br>

syntax-directed translation to act upon those requests. Here's in the
grammar we'll use, <br>

already in an LL(1) form: <br>

<br>

<span class="code">
Session &#8211;&gt;&nbsp; CommandList T_QUIT <br>
CommandList &#8211;&gt; Command CommandList | &#949;<br>
Command &#8211;&gt; Login | Get | Logout <br>
Login &#8211;&gt; User Pass <br>
User &#8211;&gt;&nbsp; T_USER T_IDENT <br>
Pass &#8211;&gt;&nbsp; T_PASS T_IDENT <br>
Get &#8211;&gt; T_GET T_IDENT MoreFiles <br>
MoreFiles &#8211;&gt; T_IDENT MoreFiles | &#949;<br>
Logout &#8211;&gt; T_LOGOUT<br>
</span>
<br>

Now, let&#8217;s see how the attributes, such as the username, filename, and
connection, can <br>

be passed around during the parsing. This recursive-descent parser is
using the <br>

lookahead/token-matching utility functions from the top-down parsing
handout. <br>
<br>

<span class="code">
<br>
static void ParseCommands() <br>
{ <br>
&nbsp;Connection *conn = NULL; <br>
&nbsp;int next; <br>
&nbsp;&nbsp; while ((next = GetLookahead()) != T_QUIT) { <br>
&nbsp;&nbsp;&nbsp; switch (next) { <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case T_USER: <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; conn =
ParseLogin(); break; <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case T_GET: <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ParseGet(conn);
break; <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case T_LOGOUT: <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
ParseLogout(conn); conn = NULL; break; <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; default: <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
ReportParseFailure("command expected", yytext); <br>
&nbsp;&nbsp;&nbsp; } <br>
&nbsp;} <br>
}<br>
&nbsp;<br>
static Connection *ParseLogin() // returns attribute of opened
connection <br>
{ <br>
&nbsp;char *user = ParseUser();&nbsp; <br>
&nbsp;char *pass = ParsePassword(); <br>
&nbsp; return Login(user, pass); // uses attributes passed up from
below <br>
}<br>
&nbsp;<br>
static char *ParseUser() // returns attribute of username given <br>
{ <br>
&nbsp;MatchToken(T_USER); <br>
&nbsp;char *str = ParseIdentifier(); // gets name from identfier child
node <br>
&nbsp; MatchToken('\n'); <br>
&nbsp;return str; <br>
}<br>
&nbsp;<br>
static char *ParsePassword() // similar to username5&nbsp; <br>
{ <br>
&nbsp;MatchToken(T_PASS); <br>
&nbsp;char *str = ParseIdentifier(); <br>
&nbsp;MatchToken('\n'); <br>
&nbsp;return str; <br>
}<br>
&nbsp;<br>
static char *ParseIdentifier() <br>
{ <br>
&nbsp;char *str = NULL; <br>
&nbsp;&nbsp;&nbsp; <br>
&nbsp;if (GetLookahead() == T_IDENT) { <br>
&nbsp;&nbsp;&nbsp; str = strdup(yytext); <br>
&nbsp;&nbsp; MatchToken(T_IDENT); <br>
&nbsp;&nbsp; } <br>
&nbsp;&nbsp; <br>
&nbsp;&nbsp; return str; // returns NULL on error <br>
}<br>
&nbsp;<br>
static void ParseGet(Connection *conn) // receives conn from above <br>
{ <br>
&nbsp;MatchToken(T_GET); <br>
&nbsp;char *filename = ParseIdentifier(); <br>
&nbsp;MatchToken('\n');&nbsp; <br>
&nbsp;Transfer(conn, filename);// reports error if conn NULL <br>
}<br>
&nbsp;<br>
static void ParseLogout(Connection *conn) // receives conn from above <br>
{ <br>
&nbsp;MatchToken(T_LOGOUT); <br>
&nbsp;MatchToken('\n'); <br>
&nbsp;Logout(conn); // reports error if conn NULL <br>
} <br>
</span>
<br>

During processing of the Login command, the parser gathers the username
and <br>

password returned from the children nodes and uses that information to
create a new <br>

connection attribute to pass up the tree.&nbsp; In this situation the
username, password, and <br>

connection are all acting as synthesized attributes, working their way
from the leaves <br>

upward to the parent. That open connection is saved and then later
passed downward <br>

into other commands. The connection is being used as an inherited
attributed when <br>

processing Get and Logout, those commands are receiving information
from the parent <br>

about parts of the parse that have already happened (its left
siblings).<br>

<br>

&nbsp;<br>

<br>

<address>Made 31 August 2011<br>
by D Bartlett.</address>

=
</body></html>